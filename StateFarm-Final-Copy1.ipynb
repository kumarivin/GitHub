{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X7\n",
      "X8\n",
      "X9\n",
      "X11\n",
      "X12\n",
      "X15\n",
      "X17\n",
      "X18\n",
      "X19\n",
      "X20\n",
      "X14\n",
      "X32\n",
      "X23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TG\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2902: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,re,csv,time\n",
    "from sklearn.metrics import log_loss, mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.preprocessing import Imputer\n",
    "from collections import Counter\n",
    "pd.options.mode.chained_assignment = None\n",
    "from sklearn.linear_model import LinearRegression,Ridge,RidgeCV,Lasso,LassoLarsIC,ElasticNet,MultiTaskLasso,LassoLars\n",
    "from sklearn.linear_model import BayesianRidge,SGDRegressor,Perceptron,PassiveAggressiveRegressor,RANSACRegressor,TheilSenRegressor\n",
    "from sklearn.cross_validation import KFold,cross_val_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "#****************************************Data Gathering\n",
    "sfdata=pd.read_csv('C:/Users/TG/Downloads/State Farm Data Science WORK SAMPLE/TrainData.csv')\n",
    "sftest=pd.read_csv('C:/Users/TG/Downloads/State Farm Data Science WORK SAMPLE/TestData.csv')\n",
    "#****************************************Data Processing\n",
    "#remove the $ & % values to convert text to number for variables X2,X4,X5,X6\n",
    "sfdata.X4.replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "sfdata.X5.replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "sfdata.X6.replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "sfdata.X1.replace(regex=True,inplace=True,to_replace=r'%',value=r'')\n",
    "sfdata.X30.replace(regex=True,inplace=True,to_replace=r'%',value=r'')\n",
    "#****************\n",
    "sftest.X4.replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "sftest.X5.replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "sftest.X6.replace(regex=True,inplace=True,to_replace=r'\\D',value=r'')\n",
    "sftest.X1.replace(regex=True,inplace=True,to_replace=r'%',value=r'')\n",
    "sftest.X30.replace(regex=True,inplace=True,to_replace=r'%',value=r'')\n",
    "\n",
    "#removing the id columns X2,X3 as they dont add any value to prediction\n",
    "sfdata.drop(sfdata.columns[[1,2]], axis=1, inplace=True)\n",
    "sftest.drop(sftest.columns[[1,2]], axis=1, inplace=True)\n",
    "#Removing the X16 as imputing will be take a complex process and will leave for some other time\n",
    "sfdata.pop('X16')\n",
    "sftest.pop('X16')\n",
    "sfdata.pop('X10')\n",
    "sftest.pop('X10')\n",
    "#Converting the variables 'X1', 'X4','X5','X6','X29','X30' to float type\n",
    "sfdata[['X1', 'X4','X5','X6','X29','X30']] = sfdata[['X1', 'X4','X5','X6','X29','X30']].astype(float)\n",
    "sftest[['X1', 'X4','X5','X6','X29','X30']] = sftest[['X1', 'X4','X5','X6','X29','X30']].astype(float)\n",
    "\n",
    "# Since X4,X5,X6 all are highly correlated with correlation score 0.99 score and leads to multi collinearity \n",
    "#I am removing taking out X4 & x6 and retaining X5\n",
    "sfdata.pop('X4')\n",
    "sfdata.pop('X6')\n",
    "sftest.pop('X4')\n",
    "sftest.pop('X6')\n",
    "\n",
    "#convert categorical variables into numeric\n",
    "# Pre-processing non-number values\n",
    "le = LabelEncoder()\n",
    "# \n",
    "for col in ['X7','X8','X9','X11','X12','X15','X17','X18','X19','X20','X14','X32','X23'] :\n",
    "    mask = sfdata[col].notnull()\n",
    "    mask1= sftest[col].notnull()\n",
    "    le.fit(list(sfdata[col])+list(sftest[col]))\n",
    "    print(col)    \n",
    "    sfdata[col][mask] = le.transform(sfdata[col][mask])\n",
    "    sftest[col][mask1] = le.transform(sftest[col][mask1])\n",
    "\n",
    "#****************************************Data Imputing\n",
    "#.Fit the knn model to predict X8 variable to impute X8 data    \n",
    "features=['X5','X7','X11','X14','X15','X17','X19','X20','X22','X23','X24','X27','X28','X29','X31','X32']\n",
    "X=sfdata[features][sfdata.X8.notnull()]\n",
    "y=list(sfdata['X8'][sfdata.X8.notnull()])\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X,y)\n",
    "sfdata['X8'][sfdata.X8.isnull()]=clf.predict(sfdata[features][sfdata.X8.isnull()])    \n",
    "\n",
    "#.Fit the knn model to predict X9 variable to impute X9 data  \n",
    "features=['X5','X8','X7','X11','X14','X15','X17','X19','X20','X22','X23','X24','X27','X28','X29','X31','X32']\n",
    "X=sfdata[features][sfdata.X9.notnull()]\n",
    "y=list(sfdata['X9'][sfdata.X9.notnull()])\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X,y)\n",
    "sfdata['X9'][sfdata.X9.isnull()]=clf.predict(sfdata[features][sfdata.X9.isnull()])\n",
    "\n",
    "#.Fit the knn model to predict X12 variable\n",
    "features=['X5','X7','X11','X14','X15','X17','X19','X20','X22','X23','X24','X27','X28','X29','X31','X32']\n",
    "X=sfdata[features][sfdata.X12.notnull()]\n",
    "y=list(sfdata['X12'][sfdata.X12.notnull()])\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X,y)\n",
    "sfdata['X12'][sfdata.X12.isnull()]=clf.predict(sfdata[features][sfdata.X12.isnull()])\n",
    "\n",
    "#.Fit the knn model to predict X18 variable\n",
    "features=['X5','X7','X11','X14','X15','X17','X19','X20','X22','X23','X24','X27','X28','X29','X31','X32']\n",
    "X=sfdata[features][sfdata.X18.notnull()]\n",
    "y=list(sfdata['X18'][sfdata.X18.notnull()])\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf.fit(X,y)\n",
    "sfdata['X18'][sfdata.X18.isnull()]=clf.predict(sfdata[features][sfdata.X18.isnull()])\n",
    "\n",
    "#.fill the null values of 25 & 26 with 0\n",
    "sfdata[['X25']]=sfdata[['X25']].fillna(0)\n",
    "sfdata[['X26']]=sfdata[['X26']].fillna(0)\n",
    "sftest[['X25']]=sftest[['X25']].fillna(0)\n",
    "sftest[['X26']]=sftest[['X26']].fillna(0)\n",
    "#.fill the null values of X30 to mean value, instead of 0 to avoid risk\n",
    "sfdata[['X30']]=sfdata[['X30']].fillna(sfdata[['X30']].mean())\n",
    "sftest[['X30']]=sftest[['X30']].fillna(sfdata[['X30']].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "K-Fold cross validation to verify consistancy in the errors\n",
      "[ 2.0807242   2.06717801  2.07778884  2.05630847  2.05507581  2.02420517\n",
      "  2.06717559  2.13268567  2.08565766  2.1101913 ]\n",
      "  -> Training time: 10.138662576675415\n",
      "Ridge\n",
      "K-Fold cross validation to verify consistancy in the errors\n",
      "[ 2.08072425  2.06717793  2.07778863  2.05630871  2.0550755   2.02420493\n",
      "  2.0671757   2.132686    2.08565769  2.11019132]\n",
      "  -> Training time: 6.448493480682373\n",
      "RidgeCV\n",
      "K-Fold cross validation to verify consistancy in the errors\n",
      "[ 2.08133823  2.0679276   2.07785048  2.05643031  2.05520314  2.0435674\n",
      "  2.06743381  2.13604821  2.08661063  2.11061678]\n",
      "  -> Training time: 12.029312372207642\n",
      "Lasso\n",
      "K-Fold cross validation to verify consistancy in the errors\n",
      "[ 2.11846821  2.09958041  2.10720546  2.09874012  2.0852247   2.05291712\n",
      "  2.10831662  2.17864988  2.12459494  2.14636007]\n",
      "  -> Training time: 11.657701969146729\n",
      "LassoLarsIC\n",
      "K-Fold cross validation to verify consistancy in the errors\n",
      "[ 2.08067892  2.06717801  2.07778884  2.05630847  2.05509518  2.02420517\n",
      "  2.06721285  2.13268567  2.08565766  2.11027197]\n",
      "  -> Training time: 8.498023271560669\n",
      "ElasticNet\n",
      "K-Fold cross validation to verify consistancy in the errors\n",
      "[ 2.33503559  2.29866009  2.30498442  2.32237961  2.28336289  2.26027516\n",
      "  2.31467089  2.39444259  2.33368928  2.34722463]\n",
      "  -> Training time: 8.166886329650879\n",
      "LassoLars\n",
      "K-Fold cross validation to verify consistancy in the errors\n",
      "[ 4.38930962  4.38094173  4.34761099  4.37128517  4.40415395  4.38533066\n",
      "  4.3731029   4.39001948  4.35897577  4.41267161]\n",
      "  -> Training time: 8.732823133468628\n",
      "BayesianRidge\n",
      "K-Fold cross validation to verify consistancy in the errors\n",
      "[ 2.08072678  2.06717383  2.07777793  2.05632141  2.05505978  2.02419239\n",
      "  2.06718143  2.13270362  2.08565968  2.11019252]\n",
      "  -> Training time: 11.86690878868103\n",
      "SGDRegressor\n",
      "K-Fold cross validation to verify consistancy in the errors\n",
      "[  1.00864963e+18   1.41360279e+18   6.20947171e+17   1.13488195e+18\n",
      "   6.64331344e+17   1.38674191e+18   1.95048548e+18   2.83766844e+18\n",
      "   2.00499885e+18   1.43759875e+18]\n",
      "  -> Training time: 9.95671010017395\n",
      "LinearRegression\n",
      "RMSE:\n",
      "2.09286684945\n",
      "Ridge\n",
      "RMSE:\n",
      "2.0928668354\n",
      "RidgeCV\n",
      "RMSE:\n",
      "2.09413487834\n",
      "Lasso\n",
      "RMSE:\n",
      "2.1300696675\n",
      "LassoLarsIC\n",
      "RMSE:\n",
      "2.09286684945\n",
      "ElasticNet\n",
      "RMSE:\n",
      "2.33385163946\n",
      "LassoLars\n",
      "RMSE:\n",
      "4.38136019742\n",
      "BayesianRidge\n",
      "RMSE:\n",
      "2.09286619964\n",
      "SGDRegressor\n",
      "RMSE:\n",
      "4.15975360925e+17\n"
     ]
    }
   ],
   "source": [
    "#************************************* Creating data set for training\n",
    "#removing rows where X30,X13 as there null\n",
    "\n",
    "train=sfdata[sfdata.X1.notnull()]\n",
    "train=train[train.X13.notnull()]\n",
    "#split the data into training and test sets\n",
    "features=list(train.columns.values)\n",
    "features.remove('X1')\n",
    "#features.remove('X30')\n",
    "X_Train,X_Test,Y_Train,Y_Test=train_test_split(train[features],train['X1'],test_size=0.33, random_state=42)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = [\n",
    "    LinearRegression(),\n",
    "    Ridge (alpha = .5),\n",
    "    RidgeCV(alphas=[0.1, 1.0, 10.0]),\n",
    "    Lasso(alpha = 0.1),\n",
    "    LassoLarsIC(),\n",
    "    ElasticNet(),    \n",
    "    LassoLars(),\n",
    "    BayesianRidge(),\n",
    "    SGDRegressor(),     \n",
    "]\n",
    "\n",
    "# Train all the classifiers and evaluate results to pick the best\n",
    "for classifier in classifiers:\n",
    "    print (classifier.__class__.__name__)\n",
    "    start = time.time()\n",
    "    scores=-cross_val_score(classifier,X_Train,(Y_Train),cv=10,scoring='mean_squared_error')\n",
    "    print('K-Fold cross validation to verify consistancy in the errors')\n",
    "    print(np.sqrt(scores))\n",
    "    classifier.fit(X_Train, Y_Train)\n",
    "    joblib.dump(classifier, 'C:/Users/TG/Downloads/State Farm Data Science WORK SAMPLE/'+classifier.__class__.__name__+'.pkl')\n",
    "    print ('  -> Training time:', time.time() - start)\n",
    "\n",
    "# Evaluation and export result\n",
    "for classifier in classifiers:\n",
    "    print (classifier.__class__.__name__)\n",
    "    #print ('Log Loss:')\n",
    "    #print (log_loss(Y_Test, classifier.predict_proba(X_Test)))\n",
    "    clf= joblib.load('C:/Users/TG/Downloads/State Farm Data Science WORK SAMPLE/'+classifier.__class__.__name__+'.pkl')\n",
    "    print ('RMSE:')\n",
    "    print (mean_squared_error(Y_Test, clf.predict(X_Test))**0.5) # RMSE\n",
    "    print\n",
    "\n",
    "    if not os.path.exists('result/'):\n",
    "        os.makedirs('result/')\n",
    "    predictions = np.column_stack((clf.predict(X_Test)))\n",
    "    csvfile = 'result/' + classifier.__class__.__name__ + '-submit.csv'\n",
    "    with open(csvfile, 'w') as output:\n",
    "        writer = csv.writer(output, lineterminator='\\n')\n",
    "        writer.writerow(['id','intrestrate'])\n",
    "        writer.writerows(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression\n",
      "  -> Training time: 1.1909904479980469\n",
      "BayesianRidge\n",
      "  -> Training time: 1.8241329193115234\n",
      "LinearRegression\n",
      "BayesianRidge\n"
     ]
    }
   ],
   "source": [
    "# Based on above results except for the SGDRegressor all other models are consistantly performing , \n",
    "#so I am choosing LinearRegression() & Bayesianridge() to fit entire test data and extract the results from test data\n",
    "train=sfdata[sfdata.X1.notnull()]\n",
    "train=train[train.X13.notnull()]\n",
    "#split the data into training and test sets\n",
    "features=list(train.columns.values)\n",
    "features.remove('X1')\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = [\n",
    "    LinearRegression(),\n",
    "    BayesianRidge()\n",
    "]\n",
    "\n",
    "# Train all the classifiers and evaluate results to pick the best\n",
    "for classifier in classifiers:\n",
    "    print (classifier.__class__.__name__)\n",
    "    start = time.time()\n",
    "    classifier.fit(train[features],train['X1'])\n",
    "    joblib.dump(classifier, 'C:/Users/TG/Downloads/State Farm Data Science WORK SAMPLE/'+classifier.__class__.__name__+'_final.pkl')\n",
    "    print ('  -> Training time:', time.time() - start)\n",
    "\n",
    "    \n",
    "#Load the model and predict the results and save them to a file    \n",
    "for classifier in classifiers:\n",
    "    print (classifier.__class__.__name__)\n",
    "    clf= joblib.load('C:/Users/TG/Downloads/State Farm Data Science WORK SAMPLE/'+classifier.__class__.__name__+'_final.pkl')   \n",
    "\n",
    "    if not os.path.exists('result/'):\n",
    "        os.makedirs('result/')\n",
    "    predictions = np.column_stack((clf.predict(sftest[features])))\n",
    "    csvfile = 'result/' + classifier.__class__.__name__ + '-finalsubmit.csv'\n",
    "    with open(csvfile, 'w') as output:\n",
    "        writer = csv.writer(output, lineterminator='\\n')\n",
    "        writer.writerow(['intrest_rate'])\n",
    "        writer.writerows(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3779445055781565"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfdata['X1'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
